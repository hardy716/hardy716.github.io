---
layout: post
title: Clean Agile - Back to Basics
image: /assets/img/blog/doc/augmented-reality.png
accent_image: 
  background: url('/assets/img/sidebar/reference-room.jpg') center/cover
  overlay: false
accent_color: '#ccc'
theme_color: '#ccc'
description: >
  Dieter Schmalstieg 와  Tobias Hollerer 의  'Augmented Reality: Principles and Practice' 을 읽고 정리한 글입니다.
invert_sidebar: true
---

# Augmented Reality: Principles and Practice

최근에 많이 시청하고 있는 유튜버 ['개발자 옆 디자이너'의 영상](https://www.youtube.com/watch?v=r4dIowyDbgs)을 보고 구매하게 된 책이다.

증강 현실의 기본 원칙과 실천 측면을 꼼꼼히 다룬 책인 것 같아 AR에 관심이 있는 분들이라면 읽어보는 것을 추천한다.



* toc
{:toc}


## 📒 1장 : 증강 현실의 개요

> 먼저 온라인 정보에 대한 접근이 엄청나게 늘어나며 대규모의 정보 소비자들이 생겨났다. 이런 소비자들은 이어서 정보 제조자로 활동하며 서로 대화할 수 있게 되고, 결국 어디에서 어떤 상황에서나 커뮤니케이션을 관리할 수단까지 갖게 됐다. 그럼에도 이 모든 정보가 수집되고 작성되며 커뮤니케이션이 일어나는 물리적 세계는 사용자의 전자적 활동에 연결될 준비를 하지 못했다.

1장에서 가장 기억에 남는 내용이었다. 사실 '증강 현실이 왜 필요한가'에 대해서는 깊게 고민해 본 적이 없었기 때문에 위 문장이 좀 더 크게 다가왔던 것 같다. 이 책에 따르면 증강 현실은 물리 세계에 대해 전자적으로 강화된 단순하고 즉각적인 사용자 인터페이스를 제공함으로써 이러한 상황을 변화시킬 수 있고, 또 그 과정에서 인간의 인식과 인지를 굉장히 새로운 방식으로 확장할 수 있다고 한다.


> AR에 대해 가장 폭넓게 받아들여지는 정의는 1997년 아주마가 논문을 통해 제기했다...

원래 알고있는 내용이었지만 신기했던 점은 이 책이 아주마의 논문이 나온지 20년 뒤의 출판물임에도 불구하고 AR의 3요소에 대한 내용이 서로 완벽하게 일치했다는 점이었다. 

[Ronald T.Azuma의 조사 논문 'A Survey of Augmented Reality'를 읽고 작성한 블로그 글](https://hardy716.github.io/blog/document/2023-06-21-a-survey-of-augmented-reality/#-ar의-정의-3요소)


> 완전한 AR 시스템에는 트래킹, 등록, 시각화라는 최소한 세 가지 컴포넌트가 필요하다. 네 번째 컴포넌트인 공간 모형은 실제 세계와 가상 세계에 대한 정보를 저장한다.

[삼성 SDS의 게시글](https://www.samsungsds.com/kr/insights/augmented-reality-technology.html)에 따르면, 증강현실의 구현 시스템은 '트래킹 시스템(Tracking System), 그래픽 시스템(Graphics System), 디스플레이 시스템(Display System)'의 3가지 요소로 이루어진다고 한다. 책에서 언급한 등록과 시각화는 각각 그래픽 시스템과 디스플레이 시스템과 관련이 있으며, 추후에 더 자세히 다룰 예정이다.


> 사실, '혼합 현실'보다 '증강 현실'이란 용어를 선호하는 이들도 있는데, MR이라는 개념보다 더 폭넓기 때문이다. 이런 관점은 현실부터 가상 현실까지를 아우르는 연속체를 제안하는 밀그램과 키시노에서 유래했다. 둘은 MR의 특징을 다음과 같이 설명한다. (MR은) 완전한 현실의 환경을 완전한 가상의 환경과 연결하는 '가상 연속체'에 따른 실체와 가상 세계에서 나온다.

[정동훈 교수님의 블로그 글](https://www.donghunc.kr/single-post/2017/03/03/가상현실-증강현실-그리고-혼합현실의-이해)에 따르면, 현실과 가상현실 사이에는 가상성의 정도에 따라 현실과 더 가까울 수도 가상현실과 더 가까울 수도 있는데, 이러한 구분을 위해서 제시한 것이 '가상성의 연속성(virtuality continuum)'이라고 한다. 가상성이라는 개념은 어느 단계를 구체적으로 단절시킬 수 있는 것이 아니라, 현실에 더해서 가상의 대상물(object)이 얼마나 많이 더해지는가에 따라 가상현실에 가까워진다는 연속체적인 속성을 띈다는 주장을 한 것이다.

![ar1-1](/assets/img/blog/doc/Reality-Virtuality-Continuum.jpg){: width="80%" height="60%"}

밀그램과 키시노가 정의한 증강 현실과 아즈마가 정의한 증강 현실에는 차이가 있다는 점을 주의해야 한다. 쉽게 얘기하면, 밀그램과 키시노의 증강 현실은 현실과 가상 현실 사이에 존재하지만 현실에 좀 더 치우쳐 있고 아즈마의 증강 현실은 현실과 가상 현실 사이 그 어딘가에 존재하기만 하면 된다고 생각하면 된다. 그 외의 차이점들에 대해서는, 추후에 추가로 정리할 예정이다.


## 📒 2장 : 디스플레이

> AR이라면 대개 물리적 세상에 대한 사람의 인식 위에 시각적 정보를 얹는 것으로 생각하지만, 다른 감각 역시 중요한 역할을 할 수 있다. 물리적 세계에 대한 인간의 경험은 본질적으로 다면적이므로, 복합 증강을 지원하는 AR 디스플레이도 가능하다. 많은 현대의 AR 제품은 여러 감각을 지원해주며, 특정한 각각의 비시각적 측면에 중심을 둔 AR 개발 노력도 진행 중이다.

비시각적 범주가 결합되면 AR의 몰입도를 증가시킬 수 있다. ETRI 감성인터랙션연구그룹의 [오감으로 발전하는 미래의 ICT는 어떨까?](https://www.etri.re.kr/webzine/20190215/sub01.html)라는 제목의 게시글에서 이와 관련해 더 살펴볼 수 있다.


> 인간의 시각은 매우 섬세한 감각으로, 두뇌의 전체 감각 정보 전달에서 대략 70%를 차지한다. 그래서 AR은 인간 사용자의 시각적 인식을 증강하는 데 집중해왔다.

> 사람의 시야각은 머리 모양과 눈 위치에 따라 양쪽 눈을 합쳐서 보통 가로 200~220도에 이른다. 중심와는 1~2도에 불과하며, 중심 0.5~1도가 가장 정확하게 보인다. 중심와 바깥쪽에서는 각도가 늘어날수록 시각적 정확도가 급격히 떨어진다. 사람은 최고 50도까지 눈을 움직이고 또한 고개를 움직여 이를 보완한다. 그래서 고품질 AR이라면 시청 장치에서 정확도가 높은 부분의 해상도가 충분히 표시돼야 한다.

> 수렴 조절 불일치는 고정 초점면이 사용되는 입체 디스플레이라면 VR뿐만 아니라 AR에서도 발생한다. 그런데 이런 입체 렌더링 기능의 광학 투과 AR에서는 추가적인 연관 문제도 발생한다. 가상 증강체를 보는 것이 수렴 조절 불일치에 의한 영향을 받을 뿐만 아니라, 사용자가 실제 세계는 올바른 원근 조절 신호로 보면서도 가상 주석에 초점이 맞춰져 있어서 사용자가 실제 세계는 올바른 원근 조절 신호로 보면서도 가상 주석에 초점이 맞춰져 있어서 사용자가 디스플레이 이미지 면에 초점을 맞출 필요가 생긴다.

> 실시간으로 초점면을 바꾸는 디스플레이가 이 문제의 한 가지 해결책이 될 수 있다.

최근 애플이 [WWDC2023에서 발표한 Apple Vision Pro](https://www.apple.com/kr/newsroom/2023/06/introducing-apple-vision-pro/)의 기능 중 하나가 생각이 났다.

![ar1-2](/assets/img/blog/doc/vision-OS.png){: width="80%" height="60%"}

애플 visionOS 내부 구성을 살펴보면 Forveated Renderer가 보이는데, 간단하게 말하자면 사용자의 시선을 추적해서 사용자가 응시하고 있는 부분(Fovea: 중심시)은 고화질로, 그 외 부분(Parafovea: 주변시)은 저화질로 처리하는 기술이다. [visualcamp의 게시글](https://visual.camp/ko/05-vr시선추적기술-foveated-rendering/)에 따르면, 이러한 포비티드 랜더링 기술은 그래픽의 성능을 높여주고 눈의 피로도를 줄여줄 수 있다고 한다.


> 광학 투과(OST) 디스플레이는 광학적 요소를 사용해 사용자에게 보이는 실제 세꼐와 컴퓨터로 생성한 이미지를 합쳐준다.

> 비디오 투과 디스플레이는 실제 세계를 비디오 카메라로 잡아내고 그래픽 프로세서를 이용해 전자적으로 결과 이미지를 변형함으로써 사용자에게 실제와 가상의 이미지를 합성해 전달한다.

앞서 작성했던 Azuma의 논문에서도 알 수 있듯이, 실제 환경과 가상 환경을 합치기 위해서 광학 투과 방식 또는 비디오 투과 방식을 사용할 수 있다. 일반적으로 광학 투과 디스플레이의 이미지 품질이 더 높지만, 비디오 투과 방식은 보다 더 정확한 등록을 해낼 수 있다는 차이점이 있다. 또한 공학 투과 디스플레이는 광학 합성기의 투명도에 좌우되지만, 비디오 투과 디스플레이는 디스플레이 자체가 충분한 명암비를 전달하기만 하면 밝기와 명암비를 임의로 변경할 수 있다. 그러나 비디오 투과 방식은 디스플레이가 작동하지 않으면 사용자가 아무것도 볼 수 없게 되기 때문에 수술이나 비행기 조종같이 목숨이 달린 상황에서는 큰 위험을 초래할 수 있다.

> OST든 VST든 모든 실제 디스플레이에는 렌즈 같은 광학적 요소가 있다. 이런 광학적 요소는 특히 넓은 시야가 필요할 때는 어안 렌즈 효과 같은 왜곡을 일으킨다. 게다가 전자적 이미지 처리 과정에서 결함의 추출과 재현이 일어날 수 있다. 예를 들어 전자식 카메라에서 폭넓게 사용되는 바이엘 마스크는 특유의 색수차를 발생시킨다. 고급 컴포넌트를 사용하고 세심하게 보정하면 이런 문제를 최소화할 수 있지만, 비용이 상승한다.

> 지연(latency)은 OST와 VST 양쪽 모두에 적용되는데, 두 경우 모두 가상 부분이 시간에 뒤처지게 되기 떄문이다. VST가 OST보다 한 가지 나은 점은 가상 요소가 매칭되도록 비디오를 지연시킬 수 있다는 점이다. 그 결과로 AR 디스플레이는 공간적 불일치를 피할 있지만, 그래도 프레젠테이션 지연이 커지는 것은 피할 수 없다.

> 높은 지연율은 VR과 AR 관람 시 멀미를 일으키는 요인 중 하나로 밝혀졌다. 다양한 연구에서 나온 데이터들이 모두 경우에 따라 다르기에 절대적인 수치를 제시하긴 어렵지만, 좀 더 심도 있는 연구에서 추론해보면 20ms에서 300ms 사이가 임계치인 것으로 보인다. 분명한 지연을 줄이기 위해서는 예측 캘리브레이션을 적극적으로 이용할 수 있으며, 그러면 시뮬레이터 멀미를 상당히 줄일 수 있다.

[KRISS 홍보관 - VR 멀미, 객관적 수치로 관리하는 기술](https://www.kriss.re.kr/gallery.es?mid=a10106030000&bid=0002&b_list=12&act=view&list_no=3839&nPage=1&vlist_no_npage=3&keyField=&orderby=)에서 VR 멀미에 관련해 더 자세한 정보를 얻을 수 있다.
